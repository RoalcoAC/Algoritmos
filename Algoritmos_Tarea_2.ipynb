{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXNcOe3XVyOLFl08Il088W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoalcoAC/Algoritmos/blob/main/Algoritmos_Tarea_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problema_3"
      ],
      "metadata": {
        "id": "YSp4EfmNU0GC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sp\n",
        "\n",
        "def gradient(f, var1, var2):\n",
        "    df_dx = sp.diff(f, var1)\n",
        "    df_dy = sp.diff(f, var2)\n",
        "    return sp.Matrix([df_dx, df_dy])\n",
        "\n",
        "def hessian_matrix(f, var1, var2):\n",
        "    h11 = sp.diff(f, var1, var1)\n",
        "    h12 = sp.diff(f, var1, var2)\n",
        "    h21 = sp.diff(f, var2, var1)\n",
        "    h22 = sp.diff(f, var2, var2)\n",
        "\n",
        "    return sp.Matrix([[h11, h12], [h21, h22]])\n",
        "\n",
        "def max_descent_direction(f, var1, var2, point):\n",
        "    x, y = sp.symbols(var1 + ' ' + var2)\n",
        "    grad = gradient(f, x, y)\n",
        "    grad_value = grad.subs({x: point[0], y: point[1]})\n",
        "    return -grad_value.normalized()\n",
        "\n",
        "def max_descent_rate(f, var1, var2, point):\n",
        "    x, y = sp.symbols(var1 + ' ' + var2)\n",
        "    grad = gradient(f, x, y)\n",
        "    grad_value = grad.subs({x: point[0], y: point[1]})\n",
        "    direction = -grad_value.normalized()\n",
        "    return grad_value.norm(), direction\n",
        "\n",
        "def directional_derivative(f, var1, var2, point, direction):\n",
        "    x, y = sp.symbols(var1 + ' ' + var2)\n",
        "    grad = gradient(f, x, y)\n",
        "    grad_value = grad.subs({x: point[0], y: point[1]})\n",
        "    direction_vector = sp.Matrix(direction)\n",
        "    return grad_value.dot(direction_vector)\n",
        "\n",
        "# Ejemplo de uso\n",
        "if __name__ == \"__main__\":\n",
        "    x, y = sp.symbols('x y')\n",
        "    f = 3*x**4 - 2*x**3*y - 4*x**2*y**2 + 5*x*y**3 + 2*y**4\n",
        "\n",
        "    hessian = hessian_matrix(f, x, y)\n",
        "\n",
        "    print(\"Matriz Hessiana:\")\n",
        "    print(hessian)\n",
        "\n",
        "    point = (1, -1)\n",
        "    rate, direction = max_descent_rate(f, 'x', 'y', point)\n",
        "\n",
        "    print(\"Tasa de descenso máxima en el punto {}: {}\".format(point, rate))\n",
        "    print(\"Dirección de máximo descenso en el punto {}: {}\".format(point, direction))\n",
        "\n",
        "    gradient_evaluated = gradient(f, x, y).subs({x: point[0], y: point[1]})\n",
        "    print(\"Gradiente en el punto {}: {}\".format(point, gradient_evaluated))\n",
        "\n",
        "    d = [1/sp.sqrt(2), -1/sp.sqrt(2)]\n",
        "    directional_derivative_value = directional_derivative(f, 'x', 'y', point, d)\n",
        "    print(\"Derivada direccional en el punto {} y en dirección del vector {}: {}\".format(point, d, directional_derivative_value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBVwBVygcC4x",
        "outputId": "51ffd0a0-d090-4d15-eb47-f67a87e19992"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz Hessiana:\n",
            "Matrix([[4*(9*x**2 - 3*x*y - 2*y**2), -6*x**2 - 16*x*y + 15*y**2], [-6*x**2 - 16*x*y + 15*y**2, 2*(-4*x**2 + 15*x*y + 12*y**2)]])\n",
            "Tasa de descenso máxima en el punto (1, -1): sqrt(194)\n",
            "Dirección de máximo descenso en el punto (1, -1): Matrix([[-5*sqrt(194)/194], [-13*sqrt(194)/194]])\n",
            "Gradiente en el punto (1, -1): Matrix([[5], [13]])\n",
            "Derivada direccional en el punto (1, -1) y en dirección del vector [sqrt(2)/2, -sqrt(2)/2]: -4*sqrt(2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Problema_4"
      ],
      "metadata": {
        "id": "lwCjn-fOcNCX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sympy as sp\n",
        "\n",
        "def gradient(f, var1, var2):\n",
        "    df_dx = sp.diff(f, var1)\n",
        "    df_dy = sp.diff(f, var2)\n",
        "    return sp.Matrix([df_dx, df_dy])\n",
        "\n",
        "def hessian_matrix(f, var1, var2):\n",
        "    h11 = sp.diff(f, var1, var1)\n",
        "    h12 = sp.diff(f, var1, var2)\n",
        "    h21 = sp.diff(f, var2, var1)\n",
        "    h22 = sp.diff(f, var2, var2)\n",
        "\n",
        "    return sp.Matrix([[h11, h12], [h21, h22]])\n",
        "\n",
        "# Serie de Taylor de segundo grado\n",
        "def taylor_series_second_order(f, var1, var2, point):\n",
        "    x, y = sp.symbols(var1 + ' ' + var2)\n",
        "    a, b = point\n",
        "    grad = gradient(f, x, y)\n",
        "    hessian = hessian_matrix(f, x, y)\n",
        "\n",
        "    taylor_approximation = f.subs({x: a, y: b}) + grad.dot(sp.Matrix([x - a, y - b])) + (1/2) * sp.Matrix([[x - a, y - b]]) @ hessian @ sp.Matrix([[x - a], [y - b]])\n",
        "    return taylor_approximation\n",
        "\n",
        "# Ejemplo de uso\n",
        "if __name__ == \"__main__\":\n",
        "    x, y = sp.symbols('x y')\n",
        "    f = 3*x**4 - 2*x**3*y - 4*x**2*y**2 + 5*x*y**3 + 2*y**4\n",
        "\n",
        "    point = (1, -1)\n",
        "\n",
        "    # Evaluamos la función y su gradiente en el punto (1, -1)\n",
        "    f_value = f.subs({x: point[0], y: point[1]}).evalf()\n",
        "    grad_value = gradient(f, x, y).subs({x: point[0], y: point[1]}).evalf()\n",
        "\n",
        "    # Calculamos la matriz hessiana y el término cuadrático de la aproximación\n",
        "    hessian = hessian_matrix(f, x, y).subs({x: point[0], y: point[1]}).evalf()\n",
        "    quadratic_term = (1/2) * sp.Matrix([[0.1, 0.01]]) @ hessian @ sp.Matrix([[0.1], [0.01]])\n",
        "\n",
        "    # Calculamos la aproximación de segundo grado\n",
        "    taylor_approximation = f_value + grad_value.dot(sp.Matrix([0.1, 0.01])) + quadratic_term[0]\n",
        "\n",
        "    print(\"Aproximación de segundo grado de f en el punto {}: {}\".format(point, taylor_approximation))\n",
        "\n",
        "    # Evaluamos la función en el punto (1.1, -0.99)\n",
        "    point2 = (1.1, -0.99)\n",
        "    f_value2 = f.subs({x: point2[0], y: point2[1]}).evalf()\n",
        "\n",
        "    print(\"Valor de f en el punto {}: {}\".format(point2, f_value2))\n",
        "\n",
        "    # Calculamos el error relativo entre las dos respuestas\n",
        "    error_rel = abs((f_value2 - taylor_approximation) / f_value2) * 100\n",
        "    print(\"Error relativo entre las dos respuestas: {}%\".format(error_rel))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wicFxJUSbYZR",
        "outputId": "7a068732-5efa-4a26-b00b-dcf44cb51d99"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aproximación de segundo grado de f en el punto (1, -1): -1.14570000000000\n",
            "Valor de f en el punto (1.1, -0.99): -1.13145648000000\n",
            "Error relativo entre las dos respuestas: 1.25886591767116%\n"
          ]
        }
      ]
    }
  ]
}